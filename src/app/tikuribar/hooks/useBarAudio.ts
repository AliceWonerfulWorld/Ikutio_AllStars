"use client";

import { useRef, useState, useCallback, useEffect } from 'react';

interface AudioConfig {
  sampleRate: number;
  bufferSize: number;
  channels: number;
  chunkDuration: number; // ms
}

export function useBarAudio() {
  const [isRecording, setIsRecording] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [isDeafened, setIsDeafened] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0); // éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºç”¨
  
  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const audioBuffersRef = useRef<Map<string, AudioBuffer[]>>(new Map());

  // éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç”¨ã®çŠ¶æ…‹ã‚’è¿½åŠ 
  const audioQueueRef = useRef<Array<{
    userId: string;
    username: string;
    audioData: string;
    timestamp: number;
  }>>([]);
  const isPlayingRef = useRef(false);

  // iOSæ¤œå‡º
  const isIOS = useRef(false);
  useEffect(() => {
    isIOS.current = /iPad|iPhone|iPod/.test(navigator.userAgent) || 
                    (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
  }, []);

  const config: AudioConfig = {
    sampleRate: isIOS.current ? 48000 : 16000, // iOSã¯48kHzã‚’æ¨å¥¨
    bufferSize: 1024,
    channels: 1,
    chunkDuration: isIOS.current ? 100 : 200    // iOSã¯çŸ­ã„ãƒãƒ£ãƒ³ã‚¯ã§
  };

  // WebSocketè¨­å®š
  const setWebSocket = useCallback((ws: WebSocket) => {
    wsRef.current = ws;
  }, []);

  // iOSç”¨ã®AudioContextåˆæœŸåŒ–
  const initializeAudioContext = useCallback(async () => {
    if (!audioContextRef.current) {
      // iOSã§ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å¾Œã«AudioContextã‚’ä½œæˆ
      audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: config.sampleRate,
        latencyHint: isIOS.current ? 'interactive' : 'balanced'
      });
      
      // iOSã§ã¯æœ€åˆã«resumeãŒå¿…è¦
      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume();
      }
    }
  }, [config.sampleRate]);

  // éŸ³å£°éŒ²éŸ³é–‹å§‹
  const startRecording = useCallback(async () => {
    if (isRecording) return;

    try {
      console.log('éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™...');
      
      // iOSç”¨ã®AudioContextåˆæœŸåŒ–
      await initializeAudioContext();
      
      // AudioContextãŒæ­£å¸¸ã«ä½œæˆã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
      if (!audioContextRef.current) {
        throw new Error('AudioContextã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ');
      }
      
      // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’å–å¾—ï¼ˆiOSå¯¾å¿œï¼‰
      const audioConstraints = {
        audio: {
          sampleRate: config.sampleRate,
          channelCount: config.channels,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          // iOS Safariå¯¾å¿œ
          ...(isIOS.current && {
            sampleSize: 16,
            sampleRate: { ideal: 48000, max: 48000 },
            channelCount: { ideal: 1, max: 1 }
          })
        }
      };

      console.log('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¦æ±‚:', audioConstraints);
      const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
      streamRef.current = stream;

      // éŸ³å£°ãƒ¬ãƒ™ãƒ«åˆ†æç”¨
      analyserRef.current = audioContextRef.current.createAnalyser();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);
      
      analyserRef.current.fftSize = 256;
      const bufferLength = analyserRef.current.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–
      const updateAudioLevel = () => {
        if (analyserRef.current) {
          analyserRef.current.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b) / bufferLength;
          setAudioLevel(Math.round((average / 255) * 100));
        }
      };

      const levelInterval = setInterval(updateAudioLevel, 50);

      // MediaRecorderè¨­å®šï¼ˆiOSå¯¾å¿œï¼‰
      let mimeType = 'audio/webm;codecs=opus';
      
      // iOS Safariå¯¾å¿œã®MIME type
      if (isIOS.current) {
        if (MediaRecorder.isTypeSupported('audio/mp4')) {
          mimeType = 'audio/mp4';
        } else if (MediaRecorder.isTypeSupported('audio/webm')) {
          mimeType = 'audio/webm';
        } else if (MediaRecorder.isTypeSupported('audio/wav')) {
          mimeType = 'audio/wav';
        }
      }

      console.log('ä½¿ç”¨ã™ã‚‹MIME type:', mimeType);

      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType,
        audioBitsPerSecond: isIOS.current ? 64000 : 32000  // iOSã¯é«˜ã„ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆ
      });

      let audioChunks: Blob[] = [];

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0 && !isMuted) {
          audioChunks.push(event.data);
          console.log(`éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å—ä¿¡: ${event.data.size} bytes`);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        if (audioChunks.length > 0) {
          const audioBlob = new Blob(audioChunks, { type: mimeType });
          sendAudioChunk(audioBlob);
        }
        audioChunks = [];
      };

      // iOSã§ã¯çŸ­ã„é–“éš”ã§ãƒãƒ£ãƒ³ã‚¯ã‚’é€ä¿¡
      recordingIntervalRef.current = setInterval(() => {
        if (mediaRecorderRef.current?.state === 'recording') {
          mediaRecorderRef.current.stop();
          mediaRecorderRef.current.start();
        }
      }, config.chunkDuration);

      mediaRecorderRef.current.start();
      setIsRecording(true);

      console.log('éŸ³å£°éŒ²éŸ³ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸ');

      // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°ã‚’è¿”ã™
      return () => {
        clearInterval(levelInterval);
      };

    } catch (error) {
      console.error('éŸ³å£°éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error);
      
      // iOSç‰¹æœ‰ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
      if (isIOS.current) {
        alert('iPhoneã§ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚Safariã®è¨­å®šã§ãƒã‚¤ã‚¯ã®è¨±å¯ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
      } else {
        alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
      }
    }
  }, [isRecording, isMuted, config, initializeAudioContext]);

  // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡
  const sendAudioChunk = useCallback(async (audioBlob: Blob) => {
    if (!wsRef.current || isMuted || wsRef.current.readyState !== WebSocket.OPEN) {
      return;
    }

    try {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));

      console.log(`éŸ³å£°é€ä¿¡: ${base64Audio.length} chars`);

      wsRef.current.send(JSON.stringify({
        type: 'audio_chunk',
        audioData: base64Audio,
        timestamp: Date.now(),
        duration: config.chunkDuration,
        mimeType: audioBlob.type // MIME typeã‚‚é€ä¿¡
      }));

    } catch (error) {
      console.error('éŸ³å£°é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
    }
  }, [isMuted, config.chunkDuration]);

  // éŸ³å£°å—ä¿¡ï¼†å†ç”Ÿï¼ˆiOSå¯¾å¿œå¼·åŒ–ï¼‰
  const handleAudioChunk = useCallback(async (data: {
    userId: string;
    username: string;
    audioData: string;
    timestamp: number;
    mimeType?: string;
  }) => {
    console.log(`ğŸµ éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å—ä¿¡: ${data.username} (ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: ${data.audioData.length})`);
    
    // è‡ªåˆ†ã®éŸ³å£°ã¯å†ç”Ÿã—ãªã„ï¼ˆã‚¨ã‚³ãƒ¼é˜²æ­¢ï¼‰
    const currentUserId = (window as any).currentUserId;
    if (data.userId === currentUserId) {
      console.log('è‡ªåˆ†ã®éŸ³å£°ãªã®ã§å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—');
      return;
    }

    // ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼OFFãƒã‚§ãƒƒã‚¯ï¼ˆäºŒé‡ãƒã‚§ãƒƒã‚¯ï¼‰
    if (isDeafened) {
      console.log('ğŸ”‡ ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼OFFã®ãŸã‚å†ç”Ÿã‚¹ã‚­ãƒƒãƒ—');
      return;
    }

    // ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‹ã‚‰ã‚‚ç¢ºèª
    if ((window as any).isDeafened) {
      console.log('ğŸ”‡ ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹: ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼OFFã®ãŸã‚å†ç”Ÿã‚¹ã‚­ãƒƒãƒ—');
      return;
    }

    // ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    audioQueueRef.current.push(data);
    
    // æ—¢ã«å†ç”Ÿä¸­ã®å ´åˆã¯ãƒªã‚¿ãƒ¼ãƒ³
    if (isPlayingRef.current) {
      return;
    }
    
    // ã‚­ãƒ¥ãƒ¼ã‹ã‚‰é †æ¬¡å†ç”Ÿ
    processAudioQueue();
  }, [isDeafened]);

  const processAudioQueue = async () => {
    if (audioQueueRef.current.length === 0) {
      isPlayingRef.current = false;
      return;
    }
    
    isPlayingRef.current = true;
    const data = audioQueueRef.current.shift()!;
    
    // AudioContextãŒæœªåˆæœŸåŒ–ã®å ´åˆã¯ä½œæˆ
    if (!audioContextRef.current) {
      console.log('ğŸµ AudioContextã‚’æ–°è¦ä½œæˆã—ã¾ã™...');
      try {
        await initializeAudioContext();
        console.log('ğŸµ AudioContextä½œæˆæˆåŠŸ');
      } catch (error) {
        console.error('ğŸš« AudioContextä½œæˆã‚¨ãƒ©ãƒ¼:', error);
        return;
      }
    }

    // AudioContextãŒnullã®å ´åˆã¯å‡¦ç†ã‚’çµ‚äº†
    if (!audioContextRef.current) {
      console.error('ğŸš« AudioContextãŒnullã§ã™');
      return;
    }

    // AudioContextãŒsuspendedçŠ¶æ…‹ã®å ´åˆã¯å†é–‹
    if (audioContextRef.current.state === 'suspended') {
      console.log('ğŸµ AudioContextã‚’å†é–‹ã—ã¾ã™...');
      await audioContextRef.current.resume();
    }

    try {
      console.log(`ğŸµ ${data.username}ã®éŸ³å£°ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰é–‹å§‹...`);
      
      // Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
      const binaryString = atob(data.audioData);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      console.log(`ğŸµ Base64ãƒ‡ã‚³ãƒ¼ãƒ‰å®Œäº† (${bytes.length} bytes)`);

      // æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
      if (bytes.length < 100) {
        console.warn(`ğŸš« éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™ (${bytes.length} bytes) - ã‚¹ã‚­ãƒƒãƒ—`);
        return;
      }

      // iOSå¯¾å¿œã®ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†
      let audioBuffer: AudioBuffer;
      
      try {
        // ãƒ‡ã‚³ãƒ¼ãƒ‰ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†ï¼ˆiOSã§ã¯é•·ã‚ã«è¨­å®šï¼‰
        const decodePromise = audioContextRef.current.decodeAudioData(bytes.buffer.slice());
        const timeoutPromise = new Promise((_, reject) => 
          setTimeout(() => reject(new Error('Decode timeout')), isIOS.current ? 2000 : 1000)
        );
        
        audioBuffer = await Promise.race([decodePromise, timeoutPromise]) as AudioBuffer;
      } catch (decodeError) {
        console.warn('âš ï¸ AudioBufferãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—ã€ä»£æ›¿æ‰‹æ®µã‚’è©¦è¡Œ:', decodeError);
        
        // iOSç”¨ã®ä»£æ›¿æ‰‹æ®µï¼šAudioBufferã‚’æ‰‹å‹•ã§ä½œæˆ
        if (isIOS.current && audioContextRef.current) {
          try {
            // ã‚·ãƒ³ãƒ—ãƒ«ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
            const sampleRate = audioContextRef.current.sampleRate;
            const duration = 0.2; // 200ms
            const length = Math.floor(sampleRate * duration);
            
            audioBuffer = audioContextRef.current.createBuffer(1, length, sampleRate);
            const channelData = audioBuffer.getChannelData(0);
            
            // ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã§åŸ‹ã‚ã‚‹ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            for (let i = 0; i < length; i++) {
              channelData[i] = Math.sin(2 * Math.PI * 440 * i / sampleRate) * 0.1; // 440Hzã®ãƒ†ã‚¹ãƒˆãƒˆãƒ¼ãƒ³
            }
            
            console.log('ğŸµ iOSç”¨ä»£æ›¿AudioBufferä½œæˆå®Œäº†');
          } catch (fallbackError) {
            console.error('ğŸš« iOSç”¨ä»£æ›¿æ‰‹æ®µã‚‚å¤±æ•—:', fallbackError);
            return;
          }
        } else {
          return;
        }
      }
      
      // éŸ³å£°ã®é•·ã•ãƒã‚§ãƒƒã‚¯
      if (audioBuffer.duration < 0.01) {
        console.warn(`ğŸš« éŸ³å£°ãŒçŸ­ã™ãã¾ã™ (${audioBuffer.duration}ç§’) - ã‚¹ã‚­ãƒƒãƒ—`);
        return;
      }
      
      console.log(`ğŸµ AudioBufferä½œæˆæˆåŠŸ - é•·ã•: ${audioBuffer.duration.toFixed(3)}ç§’, ãƒãƒ£ãƒ³ãƒãƒ«æ•°: ${audioBuffer.numberOfChannels}, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: ${audioBuffer.sampleRate}`);
      
      // AudioContextãŒnullã§ãªã„ã“ã¨ã‚’å†ç¢ºèª
      if (!audioContextRef.current) {
        console.error('ğŸš« å†ç”Ÿæ™‚ã«AudioContextãŒnullã§ã™');
        return;
      }
      
      // éŸ³å£°å†ç”Ÿ
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);
      
      console.log(`ğŸ”Š ${data.username}ã®éŸ³å£°ã‚’å†ç”Ÿé–‹å§‹ï¼`);
      source.start();
      
      // å†ç”Ÿçµ‚äº†ã®ç¢ºèª
      source.onended = () => {
        console.log(`âœ… ${data.username}ã®éŸ³å£°å†ç”Ÿå®Œäº†`);
        setTimeout(() => processAudioQueue(), isIOS.current ? 50 : 10); // iOSã§ã¯é•·ã‚ã®é–“éš”
      };

    } catch (error: unknown) {
      // ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«ã«ä¸‹ã’ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼ã¨ã—ã¦æ‰±ã‚ãªã„ï¼‰
      console.warn('âš ï¸ éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¹ã‚­ãƒƒãƒ—:', error);
      
      const errorDetails = {
        audioDataLength: data.audioData.length,
        username: data.username,
        timestamp: data.timestamp,
        audioContextState: audioContextRef.current?.state,
        isIOS: isIOS.current,
        ...(error instanceof Error 
          ? { errorName: error.name, errorMessage: error.message }
          : error instanceof DOMException
          ? { errorName: error.name, errorMessage: error.message, errorCode: error.code }
          : { errorName: 'Unknown', errorMessage: String(error) }
        )
      };
      
      console.warn('ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼è©³ç´°:', errorDetails);
    }
  };

  // éŸ³å£°éŒ²éŸ³åœæ­¢
  const stopRecording = useCallback(() => {
    console.log('éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã™...');

    if (recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
      recordingIntervalRef.current = null;
    }

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
      });
      streamRef.current = null;
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    setIsRecording(false);
    setAudioLevel(0);
    console.log('éŸ³å£°éŒ²éŸ³ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ');
  }, []);

  // ãƒŸãƒ¥ãƒ¼ãƒˆåˆ‡ã‚Šæ›¿ãˆ
  const toggleMute = useCallback(() => {
    setIsMuted(prev => {
      const newMuted = !prev;
      console.log(`ãƒŸãƒ¥ãƒ¼ãƒˆ: ${newMuted ? 'ON' : 'OFF'}`);
      
      // WebSocketã§ãƒŸãƒ¥ãƒ¼ãƒˆçŠ¶æ…‹ã‚’é€šçŸ¥
      if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({
          type: 'toggle_mute',
          isMuted: newMuted
        }));
      }
      
      return newMuted;
    });
  }, []);

  // ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åˆ‡ã‚Šæ›¿ãˆ
  const toggleDeafen = useCallback(() => {
    setIsDeafened(prev => {
      const newDeafened = !prev;
      console.log(`ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ç„¡åŠ¹: ${newDeafened ? 'ON' : 'OFF'}`);
      
      // ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã«åŒæœŸï¼ˆWebSocketãƒ•ãƒƒã‚¯ã§å‚ç…§ã™ã‚‹ãŸã‚ï¼‰
      (window as any).isDeafened = newDeafened;
      
      return newDeafened;
    });
  }, []);

  // åˆæœŸåŒ–æ™‚ã«ã‚‚ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‚’è¨­å®š
  useEffect(() => {
    (window as any).isDeafened = isDeafened;
  }, [isDeafened]);

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      stopRecording();
    };
  }, [stopRecording]);

  return {
    // çŠ¶æ…‹
    isRecording,
    isMuted,
    isDeafened,
    audioLevel,
    
    // é–¢æ•°
    setWebSocket,
    startRecording,
    stopRecording,
    toggleMute,
    toggleDeafen,
    handleAudioChunk
  };
}