"use client";

import { useRef, useState, useCallback, useEffect } from 'react';

interface AudioConfig {
  sampleRate: number;
  bufferSize: number;
  channels: number;
  chunkDuration: number; // ms
}

export function useBarAudio() {
  const [isRecording, setIsRecording] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [isDeafened, setIsDeafened] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0); // éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºç”¨
  
  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const audioBuffersRef = useRef<Map<string, AudioBuffer[]>>(new Map());

  // éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç”¨ã®çŠ¶æ…‹ã‚’è¿½åŠ 
  const audioQueueRef = useRef<Array<{
    userId: string;
    username: string;
    audioData: string;
    timestamp: number;
  }>>([]);
  const isPlayingRef = useRef(false);

  const config: AudioConfig = {
    sampleRate: 16000,
    bufferSize: 1024,
    channels: 1,
    chunkDuration: 200    // 100ms â†’ 200ms ã«å¤‰æ›´ï¼ˆéŸ³è³ªå‘ä¸Šï¼‰
  };

  // WebSocketè¨­å®š
  const setWebSocket = useCallback((ws: WebSocket) => {
    wsRef.current = ws;
  }, []);

  // éŸ³å£°éŒ²éŸ³é–‹å§‹
  const startRecording = useCallback(async () => {
    if (isRecording) return;

    try {
      console.log('éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™...');
      
      // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’å–å¾—
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: config.sampleRate,
          channelCount: config.channels,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      streamRef.current = stream;

      // AudioContextä½œæˆ
      audioContextRef.current = new AudioContext({
        sampleRate: config.sampleRate
      });

      // éŸ³å£°ãƒ¬ãƒ™ãƒ«åˆ†æç”¨
      analyserRef.current = audioContextRef.current.createAnalyser();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);
      
      analyserRef.current.fftSize = 256;
      const bufferLength = analyserRef.current.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      // éŸ³å£°ãƒ¬ãƒ™ãƒ«ç›£è¦–
      const updateAudioLevel = () => {
        if (analyserRef.current) {
          analyserRef.current.getByteFrequencyData(dataArray);
          const average = dataArray.reduce((a, b) => a + b) / bufferLength;
          setAudioLevel(Math.round((average / 255) * 100));
        }
      };

      const levelInterval = setInterval(updateAudioLevel, 50);

      // MediaRecorderè¨­å®šã‚’ä¿®æ­£ï¼ˆ75è¡Œç›®ã‚ãŸã‚Šï¼‰
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
          ? 'audio/webm;codecs=opus'
          : MediaRecorder.isTypeSupported('audio/mp4')
          ? 'audio/mp4'
          : undefined,
        audioBitsPerSecond: 32000  // ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆã‚’ä¸Šã’ã‚‹
      });

      let audioChunks: Blob[] = [];

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0 && !isMuted) {
          audioChunks.push(event.data);
        }
      };

      mediaRecorderRef.current.onstop = () => {
        if (audioChunks.length > 0) {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          sendAudioChunk(audioBlob);
        }
        audioChunks = [];
      };

      // å®šæœŸçš„ã«éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’é€ä¿¡
      recordingIntervalRef.current = setInterval(() => {
        if (mediaRecorderRef.current?.state === 'recording') {
          mediaRecorderRef.current.stop();
          mediaRecorderRef.current.start();
        }
      }, config.chunkDuration);

      mediaRecorderRef.current.start();
      setIsRecording(true);

      console.log('éŸ³å£°éŒ²éŸ³ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸ');

      // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°ã‚’è¿”ã™
      return () => {
        clearInterval(levelInterval);
      };

    } catch (error) {
      console.error('éŸ³å£°éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error);
      alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
    }
  }, [isRecording, isMuted, config]);

  // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡
  const sendAudioChunk = useCallback(async (audioBlob: Blob) => {
    if (!wsRef.current || isMuted || wsRef.current.readyState !== WebSocket.OPEN) {
      return;
    }

    try {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));

      wsRef.current.send(JSON.stringify({
        type: 'audio_chunk',
        audioData: base64Audio,
        timestamp: Date.now(),
        duration: config.chunkDuration
      }));

    } catch (error) {
      console.error('éŸ³å£°é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
    }
  }, [isMuted, config.chunkDuration]);

  // éŸ³å£°å—ä¿¡ï¼†å†ç”Ÿ
  const handleAudioChunk = useCallback(async (data: {
    userId: string;
    username: string;
    audioData: string;
    timestamp: number;
  }) => {
    console.log(`ğŸµ éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å—ä¿¡: ${data.username} (ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: ${data.audioData.length})`);
    
    // è‡ªåˆ†ã®éŸ³å£°ã¯å†ç”Ÿã—ãªã„ï¼ˆã‚¨ã‚³ãƒ¼é˜²æ­¢ï¼‰
    const currentUserId = (window as any).currentUserId;
    if (data.userId === currentUserId) {
      console.log('è‡ªåˆ†ã®éŸ³å£°ãªã®ã§å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—');
      return;
    }

    // ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼OFFãƒã‚§ãƒƒã‚¯ï¼ˆäºŒé‡ãƒã‚§ãƒƒã‚¯ï¼‰
    if (isDeafened) {
      console.log('ğŸ”‡ ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼OFFã®ãŸã‚å†ç”Ÿã‚¹ã‚­ãƒƒãƒ—');
      return;
    }

    // ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‹ã‚‰ã‚‚ç¢ºèª
    if ((window as any).isDeafened) {
      console.log('ğŸ”‡ ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹: ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼OFFã®ãŸã‚å†ç”Ÿã‚¹ã‚­ãƒƒãƒ—');
      return;
    }

    // ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    audioQueueRef.current.push(data);
    
    // æ—¢ã«å†ç”Ÿä¸­ã®å ´åˆã¯ãƒªã‚¿ãƒ¼ãƒ³
    if (isPlayingRef.current) {
      return;
    }
    
    // ã‚­ãƒ¥ãƒ¼ã‹ã‚‰é †æ¬¡å†ç”Ÿ
    processAudioQueue();
  }, [isDeafened]);

  const processAudioQueue = async () => {
    if (audioQueueRef.current.length === 0) {
      isPlayingRef.current = false;
      return;
    }
    
    isPlayingRef.current = true;
    const data = audioQueueRef.current.shift()!;
    
    // AudioContextãŒæœªåˆæœŸåŒ–ã®å ´åˆã¯ä½œæˆ
    if (!audioContextRef.current) {
      console.log('ğŸµ AudioContextã‚’æ–°è¦ä½œæˆã—ã¾ã™...');
      try {
        audioContextRef.current = new AudioContext({
          sampleRate: config.sampleRate
        });
        console.log('ğŸµ AudioContextä½œæˆæˆåŠŸ');
      } catch (error) {
        console.error('ğŸš« AudioContextä½œæˆã‚¨ãƒ©ãƒ¼:', error);
        return;
      }
    }

    // AudioContextãŒsuspendedçŠ¶æ…‹ã®å ´åˆã¯å†é–‹
    if (audioContextRef.current.state === 'suspended') {
      console.log('ğŸµ AudioContextã‚’å†é–‹ã—ã¾ã™...');
      await audioContextRef.current.resume();
    }

    try {
      console.log(`ğŸµ ${data.username}ã®éŸ³å£°ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰é–‹å§‹...`);
      
      // Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
      const binaryString = atob(data.audioData);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      console.log(`ğŸµ Base64ãƒ‡ã‚³ãƒ¼ãƒ‰å®Œäº† (${bytes.length} bytes)`);

      // æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
      if (bytes.length < 100) {
        console.warn(`ğŸš« éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™ (${bytes.length} bytes) - ã‚¹ã‚­ãƒƒãƒ—`);
        return;
      }

      // WebMéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
      console.log('ğŸµ AudioBufferãƒ‡ã‚³ãƒ¼ãƒ‰é–‹å§‹...');
      
      // ãƒ‡ã‚³ãƒ¼ãƒ‰ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†
      const decodePromise = audioContextRef.current.decodeAudioData(bytes.buffer.slice());
      const timeoutPromise = new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Decode timeout')), 1000)
      );
      
      const audioBuffer = await Promise.race([decodePromise, timeoutPromise]) as AudioBuffer;
      
      // éŸ³å£°ã®é•·ã•ãƒã‚§ãƒƒã‚¯
      if (audioBuffer.duration < 0.01) {
        console.warn(`ğŸš« éŸ³å£°ãŒçŸ­ã™ãã¾ã™ (${audioBuffer.duration}ç§’) - ã‚¹ã‚­ãƒƒãƒ—`);
        return;
      }
      
      console.log(`ğŸµ AudioBufferä½œæˆæˆåŠŸ - é•·ã•: ${audioBuffer.duration.toFixed(3)}ç§’, ãƒãƒ£ãƒ³ãƒãƒ«æ•°: ${audioBuffer.numberOfChannels}, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: ${audioBuffer.sampleRate}`);
      
      // éŸ³å£°å†ç”Ÿ
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);
      
      console.log(`ğŸ”Š ${data.username}ã®éŸ³å£°ã‚’å†ç”Ÿé–‹å§‹ï¼`);
      source.start();
      
      // å†ç”Ÿçµ‚äº†ã®ç¢ºèª
      source.onended = () => {
        console.log(`âœ… ${data.username}ã®éŸ³å£°å†ç”Ÿå®Œäº†`);
        setTimeout(() => processAudioQueue(), 10); // å°‘ã—é–“éš”ã‚’ç©ºã‘ã¦æ¬¡ã‚’å†ç”Ÿ
      };

    } catch (error: unknown) {
      // ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«ã«ä¸‹ã’ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼ã¨ã—ã¦æ‰±ã‚ãªã„ï¼‰
      console.warn('âš ï¸ éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¹ã‚­ãƒƒãƒ—:', error);
      
      const errorDetails = {
        audioDataLength: data.audioData.length,
        username: data.username,
        timestamp: data.timestamp,
        audioContextState: audioContextRef.current?.state,
        ...(error instanceof Error 
          ? { errorName: error.name, errorMessage: error.message }
          : error instanceof DOMException
          ? { errorName: error.name, errorMessage: error.message, errorCode: error.code }
          : { errorName: 'Unknown', errorMessage: String(error) }
        )
      };
      
      console.warn('ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼è©³ç´°:', errorDetails);
      
      // ã‚¨ãƒ©ãƒ¼ãŒç¶šãå ´åˆã®ã¿ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦å‡ºåŠ›
      // ã“ã®éƒ¨åˆ†ã¯ã€useBarAudioå†…ã§ã¯ãªãã€ã“ã®é–¢æ•°å†…ã§ç®¡ç†ã™ã‚‹æ–¹ãŒé©åˆ‡ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
      // ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ã§ã¯ã€useBarAudioå†…ã§lastDecodeErrorã‚’è¿½åŠ ã—ã¦ã„ã¾ã™ãŒã€
      // ã“ã®é–¢æ•°å†…ã§ã¯ãã®å¤‰æ•°ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚
      // ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€useBarAudioå†…ã«lastDecodeErrorã‚’è¿½åŠ ã™ã‚‹ã‹ã€
      // ã“ã®é–¢æ•°å†…ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã‚’ç®¡ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
      // ã“ã“ã§ã¯ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã«è­¦å‘Šã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚
    }
  };

  // éŸ³å£°éŒ²éŸ³åœæ­¢
  const stopRecording = useCallback(() => {
    console.log('éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã™...');

    if (recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
      recordingIntervalRef.current = null;
    }

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
      });
      streamRef.current = null;
    }

    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    setIsRecording(false);
    setAudioLevel(0);
    console.log('éŸ³å£°éŒ²éŸ³ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ');
  }, []);

  // ãƒŸãƒ¥ãƒ¼ãƒˆåˆ‡ã‚Šæ›¿ãˆ
  const toggleMute = useCallback(() => {
    setIsMuted(prev => {
      const newMuted = !prev;
      console.log(`ãƒŸãƒ¥ãƒ¼ãƒˆ: ${newMuted ? 'ON' : 'OFF'}`);
      
      // WebSocketã§ãƒŸãƒ¥ãƒ¼ãƒˆçŠ¶æ…‹ã‚’é€šçŸ¥
      if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({
          type: 'toggle_mute',
          isMuted: newMuted
        }));
      }
      
      return newMuted;
    });
  }, []);

  // ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼åˆ‡ã‚Šæ›¿ãˆ
  const toggleDeafen = useCallback(() => {
    setIsDeafened(prev => {
      const newDeafened = !prev;
      console.log(`ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ç„¡åŠ¹: ${newDeafened ? 'ON' : 'OFF'}`);
      
      // ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã«åŒæœŸï¼ˆWebSocketãƒ•ãƒƒã‚¯ã§å‚ç…§ã™ã‚‹ãŸã‚ï¼‰
      (window as any).isDeafened = newDeafened;
      
      return newDeafened;
    });
  }, []);

  // åˆæœŸåŒ–æ™‚ã«ã‚‚ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‚’è¨­å®š
  useEffect(() => {
    (window as any).isDeafened = isDeafened;
  }, [isDeafened]);

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      stopRecording();
    };
  }, [stopRecording]);

  return {
    // çŠ¶æ…‹
    isRecording,
    isMuted,
    isDeafened,
    audioLevel,
    
    // é–¢æ•°
    setWebSocket,
    startRecording,
    stopRecording,
    toggleMute,
    toggleDeafen,
    handleAudioChunk
  };
}